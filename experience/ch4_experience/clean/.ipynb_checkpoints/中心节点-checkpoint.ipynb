{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中心节点操作流程\n",
    "- 轨迹生成\n",
    "- 聚类操作（kmedoids），但此时的聚类结果是无序的\n",
    "- 原始数据网格化\n",
    "- 聚类得到簇心结果，然后将所有网格化数据对这些簇心进行比较，从而得到有序的聚类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "from hausdorff import hausdorff_distance\n",
    "\n",
    "from Bio.Cluster import kmedoids\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_NUM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPara(k):\n",
    "    allPara = []\n",
    "    with open('para/node1paraK'+str(k)+'.pickle', 'rb') as f:\n",
    "        para = pickle.load(f)\n",
    "    allPara.append(para)\n",
    "    with open('para/node2paraK'+str(k)+'.pickle', 'rb') as f:\n",
    "        para = pickle.load(f)\n",
    "    allPara.append(para)\n",
    "    with open('para/node3paraK'+str(k)+'.pickle', 'rb') as f:\n",
    "        para = pickle.load(f)\n",
    "    allPara.append(para)\n",
    "    return allPara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    \n",
    "    return hausdorff_distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distMatrix(data):\n",
    "    length = len(data)\n",
    "    mat = [[]]\n",
    "    for i in range(1,length):\n",
    "        tmp = []\n",
    "        for j in range(i):\n",
    "            tmp.append(dist(np.array(data[i]),np.array(data[j])))\n",
    "        mat.append(tmp) \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  clusterid 中的类号是指的是代表聚类中心的元素号。\n",
    "def cluster(K,mat):\n",
    "    clusterid, error, nfound = kmedoids(mat,K,npass = 100)\n",
    "    return clusterid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(data,labels):\n",
    "    loss = 0\n",
    "    for i in range(len(data)):\n",
    "        loss = loss + dist(np.array(data[i]),np.array(data[labels[i]]))\n",
    "    loss = loss / len(data)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseK(data,K,mat):\n",
    "    x = np.arange(3,K+1)\n",
    "    y = np.zeros(len(x))\n",
    "    for k in range(3,K+1):\n",
    "        labels = cluster(data,k,mat)\n",
    "        y[k-3] = cost(data, labels)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('cost')\n",
    "    plt.grid(True)\n",
    "    plt.plot(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2array(df):\n",
    "    # 将数据以 ndarray 的形式读入内存\n",
    "    # [[x1,x2,...,x500,y1,y2,...,y500],[],...]\n",
    "    i = 0\n",
    "    data = np.array([])\n",
    "    while i <= len(df)-1:\n",
    "        arr_x = np.array(df['x'][i:i+POINTS_NUM_PER_TR])\n",
    "        arr_y = np.array(df['y'][i:i+POINTS_NUM_PER_TR])\n",
    "        arr = np.append(arr_x,arr_y)\n",
    "        if len(data)==0:\n",
    "            data = np.array([arr])\n",
    "        else:\n",
    "            data = np.append(data,[arr],axis=0)\n",
    "        i+=POINTS_NUM_PER_TR\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(data):\n",
    "    \n",
    "    # 网格坐标化\n",
    "    data = np.round(data)\n",
    "    tr_point = [    [  (data[j][i],data[j][i+POINTS_NUM_PER_TR])    for i in range(POINTS_NUM_PER_TR)]     \n",
    "                           for j in range(len(data))]\n",
    "    \n",
    "    \n",
    "    # 去掉连续落在同一区间上的点\n",
    "    for i in range(len(tr_point)):\n",
    "        tmp = []\n",
    "        l = tr_point[i].copy()\n",
    "        for j in range(POINTS_NUM_PER_TR-1):\n",
    "            if l[j] == l[j+1]:\n",
    "                tmp.append(j)\n",
    "        tr_point[i] = [l[i] for i in range(POINTS_NUM_PER_TR) if i not in tmp]\n",
    "        \n",
    "    # 防止出现跨越的点\n",
    "    for i in range(len(tr_point)):\n",
    "        tmp = tr_point[i].copy()  # [(),(),...,()]\n",
    "        count = 0 # 添加的点造成的偏移\n",
    "        for j in range(len(tmp) - 1):\n",
    "            now_p = tmp[j]\n",
    "            next_p = tmp[j + 1]\n",
    "            if not(tr_point[i][j + count] == now_p and tr_point[i][j + count + 1] == next_p):\n",
    "                print('WRONGGGGG: ',now_p,next_p,tr_point[i][j + count],tr_point[i][j + count],)\n",
    "                break\n",
    "            if now_p[0] == next_p[0] and abs(now_p[1] - next_p[1]) == 1:\n",
    "                continue\n",
    "            elif abs(now_p[0] - next_p[0]) == 1 and now_p[1] == next_p[1]:\n",
    "                continue   \n",
    "            else:\n",
    "                # print(now_p,next_p)\n",
    "                delta_x = int(abs(now_p[0] - next_p[0]))\n",
    "                delta_y = int(abs(now_p[1] - next_p[1]))\n",
    "                if delta_x == 0:\n",
    "                    step = (next_p[1] - now_p[1]) / delta_y\n",
    "                    for k in range(1,delta_y,1):\n",
    "                        tr_point[i].insert(j + count + k,(now_p[0],now_p[1] + k * step))\n",
    "                    count = count + delta_y - 1\n",
    "                    continue\n",
    "                elif delta_y == 0:\n",
    "                    step = (next_p[0] - now_p[0])/delta_x\n",
    "                    for k in range(1,delta_x,1):\n",
    "                        tr_point[i].insert(j + count + k,(now_p[0] + k * step,now_p[1]))\n",
    "                    count = count + delta_x - 1\n",
    "                    continue\n",
    "                else:\n",
    "                    step_x = (next_p[0] - now_p[0])/delta_x\n",
    "                    step_y = (next_p[1] - now_p[1]) / delta_y\n",
    "                    k = 1\n",
    "                    while delta_x != 0 and delta_y != 0:\n",
    "                        tr_point[i].insert(j + count + 1,(now_p[0] + k * step_x,now_p[1]))\n",
    "                        tr_point[i].insert(j + count + 2,(now_p[0] + k * step_x,now_p[1] + k * step_y))\n",
    "                        count = count + 2\n",
    "                        k = k + 1\n",
    "                        delta_x = delta_x - 1\n",
    "                        delta_y = delta_y - 1\n",
    "                    if delta_x == 0 and delta_y == 0:\n",
    "                        tr_point[i].pop(j + count)\n",
    "                        count = count - 1\n",
    "                    elif delta_x == 0:\n",
    "                        step = (next_p[1] - now_p[1]) / delta_y\n",
    "                        for k in range(1,delta_y,1):\n",
    "                            tr_point[i].insert(j + count + k,(now_p[0],now_p[1] + k * step))\n",
    "                        count = count + delta_y - 1\n",
    "                        continue\n",
    "                    elif delta_y == 0:\n",
    "                        step = (next_p[0] - now_p[0])/delta_x\n",
    "                        for k in range(1,delta_x,1):\n",
    "                            tr_point[i].insert(j + count + k,(now_p[0] + k * step,now_p[1]))\n",
    "                        count = count + delta_x - 1\n",
    "                        continue\n",
    "                        \n",
    "    return tr_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDiscTr(data):\n",
    "    for index in range(len(data)):\n",
    "        tr = data[index]\n",
    "        for i in range(len(tr)-1):\n",
    "            nowP = tr[i]\n",
    "            nextP = tr[i+1]\n",
    "            if np.abs(nextP[0]-nowP[0])+np.abs(nextP[1]-nowP[1]) > 1:\n",
    "                print('wroooooooooooooong!!!')\n",
    "                print(nowP,nextP,index)\n",
    "            if np.abs(nextP[0]-nowP[0])+np.abs(nextP[1]-nowP[1]) == 0:\n",
    "                print('wroooooooooooooong!!!')\n",
    "                print(nowP,nextP,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RI(a,b):\n",
    "    ss = 0\n",
    "    dd = 0\n",
    "    sum = 0\n",
    "    for com in combinations(range(len(a)),2):\n",
    "        sum = sum + 1\n",
    "        if (a[com[0]] == a[com[1]]) and (b[com[0]] == b[com[1]]):\n",
    "            ss = ss + 1\n",
    "        if (a[com[0]] != a[com[1]]) and (b[com[0]] != b[com[1]]):\n",
    "            dd = dd + 1\n",
    "    return (ss + dd) / sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stableClustering(data,k,mat):\n",
    "    labels = cluster(k,mat)  # [121,111,123,123,121,111,...]\n",
    "    min_cost = cost(data,labels)\n",
    "    for i in range(50): # 取50次聚类中损失函数最小的\n",
    "        labels_ = cluster(k,mat)\n",
    "        cost_ = cost(data,labels_)\n",
    "        if cost_ < min_cost:\n",
    "            labels = labels_\n",
    "            min_cost = cost_\n",
    "    print('min_cost:'+str(min_cost))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelResult(originalData,data,centers):\n",
    "    result = []\n",
    "    for i in originalData:\n",
    "        distArr = []\n",
    "        for j in range(len(centers)):\n",
    "            distArr.append(hausdorff_distance(np.array(i),np.array(data[centers[j]])))\n",
    "        minDist = np.min(distArr)\n",
    "        result.append(distArr.index(minDist))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trGendrator(allPara):\n",
    "    returnTr = []\n",
    "    for node in range(NODE_NUM):\n",
    "        # 每个节点\n",
    "        nodePara = allPara[node]\n",
    "        for j in range(len(nodePara)):\n",
    "            \n",
    "           \n",
    "            # 每个子簇\n",
    "            cPara = nodePara[j]\n",
    "            \n",
    "            firstPoints = cPara['firstP']\n",
    "            lastPoints = cPara['lastP']\n",
    "            allState = cPara['allS']\n",
    "            transMatrix = pd.DataFrame(cPara['transM'].A,columns = pd.MultiIndex.from_tuples(allState),  index = pd.MultiIndex.from_tuples(allState))\n",
    "            minmaxLength = cPara['minmaxL']\n",
    "            \n",
    "            minLength = minmaxLength[0]\n",
    "            maxLength = minmaxLength[1]\n",
    "            \n",
    "            for i in range(len(firstPoints)):\n",
    "                print('第'+str(node+1)+'个节点，第'+str(j+1)+'个子簇，'+'第'+str(i+1)+'条轨迹......')\n",
    "                # 每条轨迹\n",
    "                genTr = []\n",
    "                nowP = firstPoints[i]\n",
    "                genTr.append(nowP)\n",
    "                start = time.time()\n",
    "                while(True):\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    if(end - start > 120): # 如果总是迭代不出来，补救措施\n",
    "                        print('补救一下')\n",
    "                        df = pd.read_csv('./data/node'+str(node+1)+'.csv')\n",
    "                        data = df2array(df)\n",
    "                        disc_data = discretization(data)\n",
    "                        for trrr in disc_data:\n",
    "                            if nowP == trrr[0] and len(trrr) > minLength and len(trrr) < maxLength:\n",
    "                                genTr = trrr\n",
    "                                break\n",
    "                        break\n",
    "                        \n",
    "                    pro = list(transMatrix.loc[nowP])\n",
    "                    \n",
    "                    if np.isnan(pro[0]):\n",
    "                        if len(genTr) < minLength or len(genTr) > maxLength:\n",
    "                            #print('1.长度为'+str(len(genTr))+'长度不合适')\n",
    "                            genTr = []                           \n",
    "                            nowP = firstPoints[i]\n",
    "                            genTr.append(nowP)\n",
    "                            continue\n",
    "                        else:\n",
    "                            break\n",
    "                            \n",
    "                    n = np.random.choice(len(allState),1,p = pro)\n",
    "                    nextP = allState[n[0]]\n",
    "                    \n",
    "                    # 检查是否生成了不合规的网格点\n",
    "                    if np.abs(nextP[0]-nowP[0]) + np.abs(nextP[1]-nowP[1]) > 1:\n",
    "                        print('wroooooooooooooong!!!')\n",
    "                        print(nowP,nextP,index)\n",
    "                    if np.abs(nextP[0]-nowP[0]) + np.abs(nextP[1]-nowP[1]) == 0:\n",
    "                        print('wroooooooooooooong!!!')\n",
    "                        print(nowP,nextP,index)  \n",
    "                        print(pro)\n",
    "                        \n",
    "                    if nextP in lastPoints:  # 因为有可能是last point，但是概率分布不是nan\n",
    "                        genTr.append(nextP)\n",
    "                        if len(genTr) < minLength:\n",
    "                            nowP = nextP\n",
    "                            continue\n",
    "                        elif len(genTr) > maxLength:\n",
    "                            #print('2.长度为'+str(len(genTr))+'长度不合适')\n",
    "                            genTr = []\n",
    "                            nowP = firstPoints[i]\n",
    "                            genTr.append(nowP)\n",
    "                            continue\n",
    "                        else:\n",
    "                            break\n",
    "                            \n",
    "                    genTr.append(nextP)\n",
    "                    if len(genTr) > maxLength:\n",
    "                        #print('3.长度为'+str(len(genTr))+'长度不合适')\n",
    "                        genTr = []                       \n",
    "                        nowP = firstPoints[i]\n",
    "                        genTr.append(nowP)\n",
    "                        continue\n",
    "                        \n",
    "                    nowP = nextP\n",
    "                \n",
    "                returnTr.append(genTr)\n",
    "    return returnTr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ================加载参数，生成轨迹================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    df = pd.read_csv('data/all.csv')\n",
    "\n",
    "    num_tr = int(len(df)/POINTS_NUM_PER_TR)\n",
    "    print('num_tr:'+str(num_tr))\n",
    "\n",
    "    disc_data = discretization(df2array(df))\n",
    "    return disc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS_NUM_PER_TR = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tr:532\n"
     ]
    }
   ],
   "source": [
    "DISC_DATA = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline3.pickle','rb') as f:\n",
    "    baseline3 = pickle.load(f)\n",
    "with open('baseline4.pickle','rb') as f:\n",
    "    baseline4 = pickle.load(f)\n",
    "with open('baseline5.pickle','rb') as f:\n",
    "    baseline5 = pickle.load(f)\n",
    "with open('baseline6.pickle','rb') as f:\n",
    "    baseline6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个节点，第1个子簇，第1条轨迹......\n",
      "第1个节点，第1个子簇，第2条轨迹......\n",
      "第1个节点，第1个子簇，第3条轨迹......\n",
      "第1个节点，第1个子簇，第4条轨迹......\n",
      "第1个节点，第1个子簇，第5条轨迹......\n",
      "第1个节点，第1个子簇，第6条轨迹......\n",
      "第1个节点，第1个子簇，第7条轨迹......\n",
      "第1个节点，第1个子簇，第8条轨迹......\n",
      "第1个节点，第1个子簇，第9条轨迹......\n",
      "第1个节点，第1个子簇，第10条轨迹......\n",
      "第1个节点，第1个子簇，第11条轨迹......\n",
      "第1个节点，第1个子簇，第12条轨迹......\n",
      "第1个节点，第1个子簇，第13条轨迹......\n",
      "第1个节点，第1个子簇，第14条轨迹......\n",
      "第1个节点，第1个子簇，第15条轨迹......\n",
      "第1个节点，第1个子簇，第16条轨迹......\n",
      "第1个节点，第1个子簇，第17条轨迹......\n",
      "第1个节点，第1个子簇，第18条轨迹......\n",
      "第1个节点，第1个子簇，第19条轨迹......\n",
      "第1个节点，第1个子簇，第20条轨迹......\n",
      "第1个节点，第1个子簇，第21条轨迹......\n",
      "第1个节点，第1个子簇，第22条轨迹......\n",
      "第1个节点，第1个子簇，第23条轨迹......\n",
      "第1个节点，第1个子簇，第24条轨迹......\n",
      "第1个节点，第1个子簇，第25条轨迹......\n",
      "第1个节点，第1个子簇，第26条轨迹......\n",
      "第1个节点，第1个子簇，第27条轨迹......\n",
      "第1个节点，第1个子簇，第28条轨迹......\n",
      "第1个节点，第1个子簇，第29条轨迹......\n",
      "第1个节点，第1个子簇，第30条轨迹......\n",
      "第1个节点，第1个子簇，第31条轨迹......\n",
      "第1个节点，第1个子簇，第32条轨迹......\n",
      "第1个节点，第1个子簇，第33条轨迹......\n",
      "第1个节点，第1个子簇，第34条轨迹......\n",
      "第1个节点，第1个子簇，第35条轨迹......\n",
      "第1个节点，第1个子簇，第36条轨迹......\n",
      "第1个节点，第1个子簇，第37条轨迹......\n",
      "第1个节点，第1个子簇，第38条轨迹......\n",
      "第1个节点，第1个子簇，第39条轨迹......\n",
      "第1个节点，第1个子簇，第40条轨迹......\n",
      "第1个节点，第1个子簇，第41条轨迹......\n",
      "第1个节点，第1个子簇，第42条轨迹......\n",
      "第1个节点，第1个子簇，第43条轨迹......\n",
      "第1个节点，第1个子簇，第44条轨迹......\n",
      "第1个节点，第1个子簇，第45条轨迹......\n",
      "第1个节点，第1个子簇，第46条轨迹......\n",
      "第1个节点，第1个子簇，第47条轨迹......\n",
      "第1个节点，第1个子簇，第48条轨迹......\n",
      "第1个节点，第1个子簇，第49条轨迹......\n",
      "第1个节点，第1个子簇，第50条轨迹......\n",
      "第1个节点，第1个子簇，第51条轨迹......\n",
      "第1个节点，第1个子簇，第52条轨迹......\n",
      "第1个节点，第1个子簇，第53条轨迹......\n",
      "第1个节点，第1个子簇，第54条轨迹......\n",
      "第1个节点，第1个子簇，第55条轨迹......\n",
      "第1个节点，第1个子簇，第56条轨迹......\n",
      "第1个节点，第1个子簇，第57条轨迹......\n",
      "第1个节点，第1个子簇，第58条轨迹......\n",
      "第1个节点，第1个子簇，第59条轨迹......\n",
      "第1个节点，第1个子簇，第60条轨迹......\n",
      "第1个节点，第1个子簇，第61条轨迹......\n",
      "第1个节点，第1个子簇，第62条轨迹......\n",
      "第1个节点，第1个子簇，第63条轨迹......\n",
      "第1个节点，第1个子簇，第64条轨迹......\n",
      "第1个节点，第1个子簇，第65条轨迹......\n",
      "第1个节点，第1个子簇，第66条轨迹......\n",
      "第1个节点，第1个子簇，第67条轨迹......\n",
      "第1个节点，第1个子簇，第68条轨迹......\n",
      "第1个节点，第1个子簇，第69条轨迹......\n",
      "第1个节点，第1个子簇，第70条轨迹......\n",
      "第1个节点，第1个子簇，第71条轨迹......\n",
      "第1个节点，第1个子簇，第72条轨迹......\n",
      "第1个节点，第1个子簇，第73条轨迹......\n",
      "第1个节点，第1个子簇，第74条轨迹......\n",
      "第1个节点，第1个子簇，第75条轨迹......\n",
      "第1个节点，第1个子簇，第76条轨迹......\n",
      "第1个节点，第1个子簇，第77条轨迹......\n",
      "第1个节点，第1个子簇，第78条轨迹......\n",
      "第1个节点，第1个子簇，第79条轨迹......\n",
      "第1个节点，第1个子簇，第80条轨迹......\n",
      "第1个节点，第1个子簇，第81条轨迹......\n",
      "第1个节点，第1个子簇，第82条轨迹......\n",
      "第1个节点，第1个子簇，第83条轨迹......\n",
      "第1个节点，第1个子簇，第84条轨迹......\n",
      "第1个节点，第1个子簇，第85条轨迹......\n",
      "第1个节点，第1个子簇，第86条轨迹......\n",
      "第1个节点，第1个子簇，第87条轨迹......\n",
      "第1个节点，第1个子簇，第88条轨迹......\n",
      "第1个节点，第1个子簇，第89条轨迹......\n",
      "第1个节点，第1个子簇，第90条轨迹......\n",
      "第1个节点，第1个子簇，第91条轨迹......\n",
      "第1个节点，第1个子簇，第92条轨迹......\n",
      "第1个节点，第1个子簇，第93条轨迹......\n",
      "第1个节点，第1个子簇，第94条轨迹......\n",
      "第1个节点，第1个子簇，第95条轨迹......\n",
      "第1个节点，第1个子簇，第96条轨迹......\n",
      "第1个节点，第1个子簇，第97条轨迹......\n",
      "第1个节点，第2个子簇，第1条轨迹......\n",
      "第1个节点，第2个子簇，第2条轨迹......\n",
      "第1个节点，第2个子簇，第3条轨迹......\n",
      "第1个节点，第2个子簇，第4条轨迹......\n",
      "第1个节点，第2个子簇，第5条轨迹......\n",
      "第1个节点，第2个子簇，第6条轨迹......\n",
      "第1个节点，第2个子簇，第7条轨迹......\n",
      "第1个节点，第2个子簇，第8条轨迹......\n",
      "第1个节点，第2个子簇，第9条轨迹......\n",
      "第1个节点，第2个子簇，第10条轨迹......\n",
      "第1个节点，第2个子簇，第11条轨迹......\n",
      "第1个节点，第2个子簇，第12条轨迹......\n",
      "第1个节点，第2个子簇，第13条轨迹......\n",
      "第1个节点，第2个子簇，第14条轨迹......\n",
      "第1个节点，第2个子簇，第15条轨迹......\n",
      "第1个节点，第2个子簇，第16条轨迹......\n",
      "第1个节点，第2个子簇，第17条轨迹......\n",
      "第1个节点，第2个子簇，第18条轨迹......\n",
      "第1个节点，第2个子簇，第19条轨迹......\n",
      "第1个节点，第2个子簇，第20条轨迹......\n",
      "第1个节点，第2个子簇，第21条轨迹......\n",
      "第1个节点，第2个子簇，第22条轨迹......\n",
      "第1个节点，第2个子簇，第23条轨迹......\n",
      "第1个节点，第2个子簇，第24条轨迹......\n",
      "第1个节点，第2个子簇，第25条轨迹......\n",
      "第1个节点，第2个子簇，第26条轨迹......\n",
      "第1个节点，第2个子簇，第27条轨迹......\n",
      "第1个节点，第2个子簇，第28条轨迹......\n",
      "第1个节点，第2个子簇，第29条轨迹......\n",
      "第1个节点，第2个子簇，第30条轨迹......\n",
      "第1个节点，第2个子簇，第31条轨迹......\n",
      "第1个节点，第2个子簇，第32条轨迹......\n",
      "第1个节点，第2个子簇，第33条轨迹......\n",
      "第1个节点，第2个子簇，第34条轨迹......\n",
      "第1个节点，第2个子簇，第35条轨迹......\n",
      "第1个节点，第2个子簇，第36条轨迹......\n",
      "第1个节点，第2个子簇，第37条轨迹......\n",
      "第1个节点，第2个子簇，第38条轨迹......\n",
      "第1个节点，第2个子簇，第39条轨迹......\n",
      "第1个节点，第2个子簇，第40条轨迹......\n",
      "第1个节点，第2个子簇，第41条轨迹......\n",
      "第1个节点，第2个子簇，第42条轨迹......\n",
      "第1个节点，第2个子簇，第43条轨迹......\n",
      "第1个节点，第2个子簇，第44条轨迹......\n",
      "第1个节点，第2个子簇，第45条轨迹......\n",
      "第1个节点，第2个子簇，第46条轨迹......\n",
      "第1个节点，第2个子簇，第47条轨迹......\n",
      "第1个节点，第2个子簇，第48条轨迹......\n",
      "第1个节点，第3个子簇，第1条轨迹......\n",
      "第1个节点，第3个子簇，第2条轨迹......\n",
      "第1个节点，第3个子簇，第3条轨迹......\n",
      "第1个节点，第3个子簇，第4条轨迹......\n",
      "第1个节点，第3个子簇，第5条轨迹......\n",
      "第1个节点，第3个子簇，第6条轨迹......\n",
      "第1个节点，第3个子簇，第7条轨迹......\n",
      "第1个节点，第3个子簇，第8条轨迹......\n",
      "第1个节点，第3个子簇，第9条轨迹......\n",
      "第1个节点，第3个子簇，第10条轨迹......\n",
      "第1个节点，第3个子簇，第11条轨迹......\n",
      "第1个节点，第3个子簇，第12条轨迹......\n",
      "第1个节点，第3个子簇，第13条轨迹......\n",
      "第1个节点，第3个子簇，第14条轨迹......\n",
      "第1个节点，第3个子簇，第15条轨迹......\n",
      "第1个节点，第3个子簇，第16条轨迹......\n",
      "第1个节点，第3个子簇，第17条轨迹......\n",
      "第1个节点，第3个子簇，第18条轨迹......\n",
      "第1个节点，第3个子簇，第19条轨迹......\n",
      "第1个节点，第3个子簇，第20条轨迹......\n",
      "第1个节点，第3个子簇，第21条轨迹......\n",
      "第1个节点，第3个子簇，第22条轨迹......\n",
      "第1个节点，第3个子簇，第23条轨迹......\n",
      "第1个节点，第3个子簇，第24条轨迹......\n",
      "第1个节点，第3个子簇，第25条轨迹......\n",
      "第1个节点，第3个子簇，第26条轨迹......\n",
      "第1个节点，第3个子簇，第27条轨迹......\n",
      "第1个节点，第3个子簇，第28条轨迹......\n",
      "第1个节点，第3个子簇，第29条轨迹......\n",
      "第1个节点，第3个子簇，第30条轨迹......\n",
      "第1个节点，第3个子簇，第31条轨迹......\n",
      "第1个节点，第3个子簇，第32条轨迹......\n",
      "第2个节点，第1个子簇，第1条轨迹......\n",
      "第2个节点，第1个子簇，第2条轨迹......\n",
      "第2个节点，第1个子簇，第3条轨迹......\n",
      "第2个节点，第1个子簇，第4条轨迹......\n",
      "第2个节点，第1个子簇，第5条轨迹......\n",
      "第2个节点，第1个子簇，第6条轨迹......\n",
      "第2个节点，第1个子簇，第7条轨迹......\n",
      "第2个节点，第1个子簇，第8条轨迹......\n",
      "第2个节点，第1个子簇，第9条轨迹......\n",
      "第2个节点，第1个子簇，第10条轨迹......\n",
      "第2个节点，第1个子簇，第11条轨迹......\n",
      "第2个节点，第1个子簇，第12条轨迹......\n",
      "第2个节点，第1个子簇，第13条轨迹......\n",
      "第2个节点，第1个子簇，第14条轨迹......\n",
      "第2个节点，第1个子簇，第15条轨迹......\n",
      "第2个节点，第1个子簇，第16条轨迹......\n",
      "第2个节点，第1个子簇，第17条轨迹......\n",
      "第2个节点，第1个子簇，第18条轨迹......\n",
      "第2个节点，第1个子簇，第19条轨迹......\n",
      "第2个节点，第1个子簇，第20条轨迹......\n",
      "第2个节点，第1个子簇，第21条轨迹......\n",
      "第2个节点，第1个子簇，第22条轨迹......\n",
      "第2个节点，第1个子簇，第23条轨迹......\n",
      "第2个节点，第1个子簇，第24条轨迹......\n",
      "第2个节点，第1个子簇，第25条轨迹......\n",
      "第2个节点，第1个子簇，第26条轨迹......\n",
      "第2个节点，第1个子簇，第27条轨迹......\n",
      "第2个节点，第1个子簇，第28条轨迹......\n",
      "第2个节点，第1个子簇，第29条轨迹......\n",
      "第2个节点，第1个子簇，第30条轨迹......\n",
      "第2个节点，第1个子簇，第31条轨迹......\n",
      "第2个节点，第1个子簇，第32条轨迹......\n",
      "第2个节点，第1个子簇，第33条轨迹......\n",
      "第2个节点，第1个子簇，第34条轨迹......\n",
      "第2个节点，第1个子簇，第35条轨迹......\n",
      "第2个节点，第1个子簇，第36条轨迹......\n",
      "第2个节点，第1个子簇，第37条轨迹......\n",
      "第2个节点，第1个子簇，第38条轨迹......\n",
      "第2个节点，第1个子簇，第39条轨迹......\n",
      "第2个节点，第1个子簇，第40条轨迹......\n",
      "第2个节点，第1个子簇，第41条轨迹......\n",
      "第2个节点，第1个子簇，第42条轨迹......\n",
      "第2个节点，第1个子簇，第43条轨迹......\n",
      "第2个节点，第1个子簇，第44条轨迹......\n",
      "第2个节点，第1个子簇，第45条轨迹......\n",
      "第2个节点，第1个子簇，第46条轨迹......\n",
      "第2个节点，第1个子簇，第47条轨迹......\n",
      "第2个节点，第1个子簇，第48条轨迹......\n",
      "第2个节点，第1个子簇，第49条轨迹......\n",
      "第2个节点，第1个子簇，第50条轨迹......\n",
      "第2个节点，第1个子簇，第51条轨迹......\n",
      "第2个节点，第1个子簇，第52条轨迹......\n",
      "第2个节点，第1个子簇，第53条轨迹......\n",
      "第2个节点，第1个子簇，第54条轨迹......\n",
      "第2个节点，第1个子簇，第55条轨迹......\n",
      "第2个节点，第1个子簇，第56条轨迹......\n",
      "第2个节点，第1个子簇，第57条轨迹......\n",
      "第2个节点，第1个子簇，第58条轨迹......\n",
      "第2个节点，第1个子簇，第59条轨迹......\n",
      "第2个节点，第1个子簇，第60条轨迹......\n",
      "第2个节点，第1个子簇，第61条轨迹......\n",
      "第2个节点，第1个子簇，第62条轨迹......\n",
      "第2个节点，第1个子簇，第63条轨迹......\n",
      "第2个节点，第1个子簇，第64条轨迹......\n",
      "第2个节点，第1个子簇，第65条轨迹......\n",
      "第2个节点，第1个子簇，第66条轨迹......\n",
      "第2个节点，第1个子簇，第67条轨迹......\n",
      "第2个节点，第1个子簇，第68条轨迹......\n",
      "第2个节点，第1个子簇，第69条轨迹......\n",
      "第2个节点，第1个子簇，第70条轨迹......\n",
      "第2个节点，第1个子簇，第71条轨迹......\n",
      "第2个节点，第1个子簇，第72条轨迹......\n",
      "第2个节点，第1个子簇，第73条轨迹......\n",
      "第2个节点，第1个子簇，第74条轨迹......\n",
      "第2个节点，第1个子簇，第75条轨迹......\n",
      "第2个节点，第1个子簇，第76条轨迹......\n",
      "第2个节点，第1个子簇，第77条轨迹......\n",
      "第2个节点，第1个子簇，第78条轨迹......\n",
      "第2个节点，第1个子簇，第79条轨迹......\n",
      "第2个节点，第1个子簇，第80条轨迹......\n",
      "第2个节点，第1个子簇，第81条轨迹......\n",
      "第2个节点，第1个子簇，第82条轨迹......\n",
      "第2个节点，第1个子簇，第83条轨迹......\n",
      "第2个节点，第1个子簇，第84条轨迹......\n",
      "第2个节点，第1个子簇，第85条轨迹......\n",
      "第2个节点，第1个子簇，第86条轨迹......\n",
      "第2个节点，第1个子簇，第87条轨迹......\n",
      "第2个节点，第1个子簇，第88条轨迹......\n",
      "第2个节点，第1个子簇，第89条轨迹......\n",
      "第2个节点，第2个子簇，第1条轨迹......\n",
      "第2个节点，第2个子簇，第2条轨迹......\n",
      "第2个节点，第2个子簇，第3条轨迹......\n",
      "第2个节点，第2个子簇，第4条轨迹......\n",
      "第2个节点，第2个子簇，第5条轨迹......\n",
      "第2个节点，第2个子簇，第6条轨迹......\n",
      "第2个节点，第2个子簇，第7条轨迹......\n",
      "第2个节点，第2个子簇，第8条轨迹......\n",
      "第2个节点，第2个子簇，第9条轨迹......\n",
      "第2个节点，第2个子簇，第10条轨迹......\n",
      "第2个节点，第2个子簇，第11条轨迹......\n",
      "第2个节点，第2个子簇，第12条轨迹......\n",
      "第2个节点，第2个子簇，第13条轨迹......\n",
      "第2个节点，第2个子簇，第14条轨迹......\n",
      "第2个节点，第2个子簇，第15条轨迹......\n",
      "第2个节点，第2个子簇，第16条轨迹......\n",
      "第2个节点，第2个子簇，第17条轨迹......\n",
      "第2个节点，第2个子簇，第18条轨迹......\n",
      "第2个节点，第2个子簇，第19条轨迹......\n",
      "第2个节点，第2个子簇，第20条轨迹......\n",
      "第2个节点，第2个子簇，第21条轨迹......\n",
      "第2个节点，第2个子簇，第22条轨迹......\n",
      "第2个节点，第2个子簇，第23条轨迹......\n",
      "第2个节点，第2个子簇，第24条轨迹......\n",
      "第2个节点，第2个子簇，第25条轨迹......\n",
      "第2个节点，第2个子簇，第26条轨迹......\n",
      "第2个节点，第2个子簇，第27条轨迹......\n",
      "第2个节点，第2个子簇，第28条轨迹......\n",
      "第2个节点，第2个子簇，第29条轨迹......\n",
      "第2个节点，第2个子簇，第30条轨迹......\n",
      "第2个节点，第2个子簇，第31条轨迹......\n",
      "第2个节点，第2个子簇，第32条轨迹......\n",
      "第2个节点，第2个子簇，第33条轨迹......\n",
      "第2个节点，第2个子簇，第34条轨迹......\n",
      "第2个节点，第2个子簇，第35条轨迹......\n",
      "第2个节点，第2个子簇，第36条轨迹......\n",
      "第2个节点，第2个子簇，第37条轨迹......\n",
      "第2个节点，第2个子簇，第38条轨迹......\n",
      "第2个节点，第2个子簇，第39条轨迹......\n",
      "第2个节点，第2个子簇，第40条轨迹......\n",
      "第2个节点，第2个子簇，第41条轨迹......\n",
      "第2个节点，第2个子簇，第42条轨迹......\n",
      "第2个节点，第2个子簇，第43条轨迹......\n",
      "第2个节点，第2个子簇，第44条轨迹......\n",
      "第2个节点，第2个子簇，第45条轨迹......\n",
      "第2个节点，第2个子簇，第46条轨迹......\n",
      "第2个节点，第3个子簇，第1条轨迹......\n",
      "第2个节点，第3个子簇，第2条轨迹......\n",
      "第2个节点，第3个子簇，第3条轨迹......\n",
      "第2个节点，第3个子簇，第4条轨迹......\n",
      "第2个节点，第3个子簇，第5条轨迹......\n",
      "第2个节点，第3个子簇，第6条轨迹......\n",
      "第2个节点，第3个子簇，第7条轨迹......\n",
      "第2个节点，第3个子簇，第8条轨迹......\n",
      "第2个节点，第3个子簇，第9条轨迹......\n",
      "第2个节点，第3个子簇，第10条轨迹......\n",
      "第2个节点，第3个子簇，第11条轨迹......\n",
      "第2个节点，第3个子簇，第12条轨迹......\n",
      "第2个节点，第3个子簇，第13条轨迹......\n",
      "第2个节点，第3个子簇，第14条轨迹......\n",
      "第2个节点，第3个子簇，第15条轨迹......\n",
      "第2个节点，第3个子簇，第16条轨迹......\n",
      "第2个节点，第3个子簇，第17条轨迹......\n",
      "第2个节点，第3个子簇，第18条轨迹......\n",
      "第2个节点，第3个子簇，第19条轨迹......\n",
      "第2个节点，第3个子簇，第20条轨迹......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个节点，第3个子簇，第21条轨迹......\n",
      "第2个节点，第3个子簇，第22条轨迹......\n",
      "第2个节点，第3个子簇，第23条轨迹......\n",
      "第2个节点，第3个子簇，第24条轨迹......\n",
      "第2个节点，第3个子簇，第25条轨迹......\n",
      "第2个节点，第3个子簇，第26条轨迹......\n",
      "第2个节点，第3个子簇，第27条轨迹......\n",
      "第2个节点，第3个子簇，第28条轨迹......\n",
      "第2个节点，第3个子簇，第29条轨迹......\n",
      "第2个节点，第3个子簇，第30条轨迹......\n",
      "第2个节点，第3个子簇，第31条轨迹......\n",
      "第2个节点，第3个子簇，第32条轨迹......\n",
      "第2个节点，第3个子簇，第33条轨迹......\n",
      "第2个节点，第3个子簇，第34条轨迹......\n",
      "第2个节点，第3个子簇，第35条轨迹......\n",
      "第2个节点，第3个子簇，第36条轨迹......\n",
      "第2个节点，第3个子簇，第37条轨迹......\n",
      "第2个节点，第3个子簇，第38条轨迹......\n",
      "第2个节点，第3个子簇，第39条轨迹......\n",
      "第2个节点，第3个子簇，第40条轨迹......\n",
      "第2个节点，第3个子簇，第41条轨迹......\n",
      "第2个节点，第3个子簇，第42条轨迹......\n",
      "第3个节点，第1个子簇，第1条轨迹......\n",
      "第3个节点，第1个子簇，第2条轨迹......\n",
      "第3个节点，第1个子簇，第3条轨迹......\n",
      "第3个节点，第1个子簇，第4条轨迹......\n",
      "第3个节点，第1个子簇，第5条轨迹......\n",
      "补救一下\n",
      "第3个节点，第1个子簇，第6条轨迹......\n",
      "第3个节点，第1个子簇，第7条轨迹......\n",
      "第3个节点，第1个子簇，第8条轨迹......\n",
      "第3个节点，第1个子簇，第9条轨迹......\n",
      "第3个节点，第1个子簇，第10条轨迹......\n",
      "第3个节点，第1个子簇，第11条轨迹......\n",
      "第3个节点，第1个子簇，第12条轨迹......\n",
      "第3个节点，第1个子簇，第13条轨迹......\n",
      "第3个节点，第1个子簇，第14条轨迹......\n",
      "第3个节点，第1个子簇，第15条轨迹......\n",
      "第3个节点，第1个子簇，第16条轨迹......\n",
      "第3个节点，第1个子簇，第17条轨迹......\n",
      "第3个节点，第1个子簇，第18条轨迹......\n",
      "第3个节点，第1个子簇，第19条轨迹......\n",
      "第3个节点，第1个子簇，第20条轨迹......\n",
      "第3个节点，第1个子簇，第21条轨迹......\n",
      "第3个节点，第1个子簇，第22条轨迹......\n",
      "第3个节点，第1个子簇，第23条轨迹......\n",
      "第3个节点，第1个子簇，第24条轨迹......\n",
      "第3个节点，第1个子簇，第25条轨迹......\n",
      "第3个节点，第1个子簇，第26条轨迹......\n",
      "第3个节点，第1个子簇，第27条轨迹......\n",
      "第3个节点，第1个子簇，第28条轨迹......\n",
      "第3个节点，第1个子簇，第29条轨迹......\n",
      "第3个节点，第1个子簇，第30条轨迹......\n",
      "第3个节点，第1个子簇，第31条轨迹......\n",
      "第3个节点，第1个子簇，第32条轨迹......\n",
      "第3个节点，第1个子簇，第33条轨迹......\n",
      "第3个节点，第1个子簇，第34条轨迹......\n",
      "第3个节点，第1个子簇，第35条轨迹......\n",
      "第3个节点，第1个子簇，第36条轨迹......\n",
      "第3个节点，第1个子簇，第37条轨迹......\n",
      "第3个节点，第1个子簇，第38条轨迹......\n",
      "第3个节点，第1个子簇，第39条轨迹......\n",
      "第3个节点，第1个子簇，第40条轨迹......\n",
      "第3个节点，第1个子簇，第41条轨迹......\n",
      "第3个节点，第1个子簇，第42条轨迹......\n",
      "第3个节点，第1个子簇，第43条轨迹......\n",
      "第3个节点，第1个子簇，第44条轨迹......\n",
      "第3个节点，第1个子簇，第45条轨迹......\n",
      "第3个节点，第1个子簇，第46条轨迹......\n",
      "第3个节点，第2个子簇，第1条轨迹......\n",
      "第3个节点，第2个子簇，第2条轨迹......\n",
      "第3个节点，第2个子簇，第3条轨迹......\n",
      "第3个节点，第2个子簇，第4条轨迹......\n",
      "第3个节点，第2个子簇，第5条轨迹......\n",
      "第3个节点，第2个子簇，第6条轨迹......\n",
      "第3个节点，第2个子簇，第7条轨迹......\n",
      "第3个节点，第2个子簇，第8条轨迹......\n",
      "第3个节点，第2个子簇，第9条轨迹......\n",
      "第3个节点，第2个子簇，第10条轨迹......\n",
      "第3个节点，第2个子簇，第11条轨迹......\n",
      "第3个节点，第2个子簇，第12条轨迹......\n",
      "第3个节点，第2个子簇，第13条轨迹......\n",
      "第3个节点，第2个子簇，第14条轨迹......\n",
      "第3个节点，第2个子簇，第15条轨迹......\n",
      "第3个节点，第2个子簇，第16条轨迹......\n",
      "第3个节点，第2个子簇，第17条轨迹......\n",
      "第3个节点，第2个子簇，第18条轨迹......\n",
      "第3个节点，第2个子簇，第19条轨迹......\n",
      "第3个节点，第2个子簇，第20条轨迹......\n",
      "第3个节点，第2个子簇，第21条轨迹......\n",
      "第3个节点，第2个子簇，第22条轨迹......\n",
      "第3个节点，第2个子簇，第23条轨迹......\n",
      "第3个节点，第2个子簇，第24条轨迹......\n",
      "第3个节点，第2个子簇，第25条轨迹......\n",
      "第3个节点，第2个子簇，第26条轨迹......\n",
      "第3个节点，第2个子簇，第27条轨迹......\n",
      "第3个节点，第2个子簇，第28条轨迹......\n",
      "第3个节点，第2个子簇，第29条轨迹......\n",
      "第3个节点，第2个子簇，第30条轨迹......\n",
      "第3个节点，第2个子簇，第31条轨迹......\n",
      "第3个节点，第2个子簇，第32条轨迹......\n",
      "第3个节点，第2个子簇，第33条轨迹......\n",
      "第3个节点，第2个子簇，第34条轨迹......\n",
      "第3个节点，第2个子簇，第35条轨迹......\n",
      "第3个节点，第2个子簇，第36条轨迹......\n",
      "第3个节点，第2个子簇，第37条轨迹......\n",
      "第3个节点，第2个子簇，第38条轨迹......\n",
      "第3个节点，第2个子簇，第39条轨迹......\n",
      "第3个节点，第3个子簇，第1条轨迹......\n",
      "第3个节点，第3个子簇，第2条轨迹......\n",
      "第3个节点，第3个子簇，第3条轨迹......\n",
      "第3个节点，第3个子簇，第4条轨迹......\n",
      "第3个节点，第3个子簇，第5条轨迹......\n",
      "第3个节点，第3个子簇，第6条轨迹......\n",
      "第3个节点，第3个子簇，第7条轨迹......\n",
      "第3个节点，第3个子簇，第8条轨迹......\n",
      "第3个节点，第3个子簇，第9条轨迹......\n",
      "第3个节点，第3个子簇，第10条轨迹......\n",
      "第3个节点，第3个子簇，第11条轨迹......\n",
      "第3个节点，第3个子簇，第12条轨迹......\n",
      "第3个节点，第3个子簇，第13条轨迹......\n",
      "第3个节点，第3个子簇，第14条轨迹......\n",
      "第3个节点，第3个子簇，第15条轨迹......\n",
      "第3个节点，第3个子簇，第16条轨迹......\n",
      "第3个节点，第3个子簇，第17条轨迹......\n",
      "第3个节点，第3个子簇，第18条轨迹......\n",
      "第3个节点，第3个子簇，第19条轨迹......\n",
      "第3个节点，第3个子簇，第20条轨迹......\n",
      "第3个节点，第3个子簇，第21条轨迹......\n",
      "第3个节点，第3个子簇，第22条轨迹......\n",
      "第3个节点，第3个子簇，第23条轨迹......\n",
      "第3个节点，第3个子簇，第24条轨迹......\n",
      "第3个节点，第3个子簇，第25条轨迹......\n",
      "第3个节点，第3个子簇，第26条轨迹......\n",
      "第3个节点，第3个子簇，第27条轨迹......\n",
      "第3个节点，第3个子簇，第28条轨迹......\n",
      "第3个节点，第3个子簇，第29条轨迹......\n",
      "第3个节点，第3个子簇，第30条轨迹......\n",
      "第3个节点，第3个子簇，第31条轨迹......\n",
      "第3个节点，第3个子簇，第32条轨迹......\n",
      "第3个节点，第3个子簇，第33条轨迹......\n",
      "第3个节点，第3个子簇，第34条轨迹......\n",
      "第3个节点，第3个子簇，第35条轨迹......\n",
      "第3个节点，第3个子簇，第36条轨迹......\n",
      "第3个节点，第3个子簇，第37条轨迹......\n",
      "第3个节点，第3个子簇，第38条轨迹......\n",
      "第3个节点，第3个子簇，第39条轨迹......\n",
      "第3个节点，第3个子簇，第40条轨迹......\n",
      "第3个节点，第3个子簇，第41条轨迹......\n",
      "第3个节点，第3个子簇，第42条轨迹......\n",
      "第3个节点，第3个子簇，第43条轨迹......\n",
      "第3个节点，第3个子簇，第44条轨迹......\n",
      "第3个节点，第3个子簇，第45条轨迹......\n",
      "第3个节点，第3个子簇，第46条轨迹......\n",
      "第3个节点，第3个子簇，第47条轨迹......\n",
      "第3个节点，第3个子簇，第48条轨迹......\n",
      "第3个节点，第3个子簇，第49条轨迹......\n",
      "第3个节点，第3个子簇，第50条轨迹......\n",
      "第3个节点，第3个子簇，第51条轨迹......\n",
      "第3个节点，第3个子簇，第52条轨迹......\n",
      "第3个节点，第3个子簇，第53条轨迹......\n",
      "第3个节点，第3个子簇，第54条轨迹......\n",
      "第3个节点，第3个子簇，第55条轨迹......\n",
      "第3个节点，第3个子簇，第56条轨迹......\n",
      "第3个节点，第3个子簇，第57条轨迹......\n",
      "第3个节点，第3个子簇，第58条轨迹......\n",
      "第3个节点，第3个子簇，第59条轨迹......\n",
      "第3个节点，第3个子簇，第60条轨迹......\n",
      "第3个节点，第3个子簇，第61条轨迹......\n",
      "第3个节点，第3个子簇，第62条轨迹......\n",
      "第3个节点，第3个子簇，第63条轨迹......\n",
      "第3个节点，第3个子簇，第64条轨迹......\n",
      "第3个节点，第3个子簇，第65条轨迹......\n",
      "第3个节点，第3个子簇，第66条轨迹......\n",
      "第3个节点，第3个子簇，第67条轨迹......\n",
      "第3个节点，第3个子簇，第68条轨迹......\n",
      "第3个节点，第3个子簇，第69条轨迹......\n",
      "第3个节点，第3个子簇，第70条轨迹......\n",
      "第3个节点，第3个子簇，第71条轨迹......\n",
      "第3个节点，第3个子簇，第72条轨迹......\n",
      "第3个节点，第3个子簇，第73条轨迹......\n",
      "第3个节点，第3个子簇，第74条轨迹......\n",
      "第3个节点，第3个子簇，第75条轨迹......\n",
      "第3个节点，第3个子簇，第76条轨迹......\n",
      "第3个节点，第3个子簇，第77条轨迹......\n",
      "第3个节点，第3个子簇，第78条轨迹......\n",
      "第3个节点，第3个子簇，第79条轨迹......\n",
      "第3个节点，第3个子簇，第80条轨迹......\n",
      "第3个节点，第3个子簇，第81条轨迹......\n",
      "第3个节点，第3个子簇，第82条轨迹......\n",
      "第3个节点，第3个子簇，第83条轨迹......\n",
      "第3个节点，第3个子簇，第84条轨迹......\n",
      "第3个节点，第3个子簇，第85条轨迹......\n",
      "第3个节点，第3个子簇，第86条轨迹......\n",
      "第3个节点，第3个子簇，第87条轨迹......\n",
      "第3个节点，第3个子簇，第88条轨迹......\n",
      "第3个节点，第3个子簇，第89条轨迹......\n",
      "第3个节点，第3个子簇，第90条轨迹......\n",
      "第3个节点，第3个子簇，第91条轨迹......\n",
      "第3个节点，第3个子簇，第92条轨迹......\n",
      "第3个节点，第3个子簇，第93条轨迹......\n"
     ]
    }
   ],
   "source": [
    "GEN_TR3 = trGendrator(loadPara(3))\n",
    "MAT3 = distMatrix(GEN_TR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GEN_TR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkDiscTr(GEN_TR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkResult(globalK,genTr,mat,n):\n",
    "    \n",
    "    if globalK == 3:\n",
    "        baseline = baseline3\n",
    "    elif globalK == 4:\n",
    "        baseline = baseline4\n",
    "    elif globalK == 5:\n",
    "        baseline == baseline5\n",
    "\n",
    "    ri = 0\n",
    "    ari = 0\n",
    "    N = n\n",
    "    \n",
    "    for i in range(N):\n",
    "        l = stableClustering(genTr,globalK,mat)\n",
    "        l = getLabelResult(DISC_DATA,DISC_DATA,list(set(l)))\n",
    "        ri = ri + RI(baseline,l)\n",
    "        ari = ari + adjusted_rand_score(baseline,l)\n",
    "        print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "    print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.长度为113长度不合适\n",
      "3.长度为113长度不合适\n",
      "3.长度为113长度不合适\n",
      "2.长度为103长度不合适\n",
      "3.长度为88长度不合适\n",
      "3.长度为88长度不合适\n",
      "3.长度为88长度不合适\n",
      "3.长度为76长度不合适\n",
      "3.长度为98长度不合适\n",
      "3.长度为82长度不合适\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-cdb5a76d0a03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mGEN_TR6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrGendrator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadPara\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mGEN_TR7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrGendrator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadPara\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mGEN_TR8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrGendrator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadPara\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mMAT3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGEN_TR3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mMAT4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGEN_TR4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-3e33bde028cb>\u001b[0m in \u001b[0;36mtrGendrator\u001b[1;34m(allPara)\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallState\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[0mnextP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallState\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnextP\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlastPoints\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 因为有可能是last point，但是概率分布不是nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GEN_TR3 = trGendrator(loadPara(3))\n",
    "GEN_TR4 = trGendrator(loadPara(4))\n",
    "GEN_TR5 = trGendrator(loadPara(5))\n",
    "GEN_TR6 = trGendrator(loadPara(6))\n",
    "GEN_TR7 = trGendrator(loadPara(7))\n",
    "GEN_TR8 = trGendrator(loadPara(8))\n",
    "MAT3 = distMatrix(GEN_TR3)\n",
    "MAT4 = distMatrix(GEN_TR4)\n",
    "MAT5 = distMatrix(GEN_TR5)\n",
    "MAT6 = distMatrix(GEN_TR6)\n",
    "MAT7 = distMatrix(GEN_TR7)\n",
    "MAT8 = distMatrix(GEN_TR8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [0, 1, 2, 1, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 1, 2, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 0, 2, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 0, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 2, 0, 0, 0, 2, 1, 2, 0, 0, 2, 2, 1, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 0, 2, 0, 0, 1, 1, 2, 1, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.129423169921465\n",
      "0.9203800461605992 0.8266472482819213\n",
      "8.129423169921465\n",
      "0.9203800461605992 0.8266472482819213\n",
      "8.129423169921465\n",
      "0.9203800461605992 0.8266472482819213\n",
      "0.9203800461605992 0.8266472482819213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR3,K,MAT3)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.622907177438549\n",
      "0.8838055590954789 0.7503815568426025\n",
      "6.622907177438549\n",
      "0.8838055590954789 0.7503815568426025\n",
      "6.622907177438549\n",
      "0.8838055590954789 0.7503815568426025\n",
      "0.8838055590954789 0.7503815568426025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR4,K,MAT4)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.909399886018491\n",
      "0.91139572094077 0.8086638046827552\n",
      "6.909399886018491\n",
      "0.91139572094077 0.8086638046827552\n",
      "6.909399886018491\n",
      "0.91139572094077 0.8086638046827552\n",
      "0.91139572094077 0.8086638046827552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR5,K,MAT5)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1904000705326725\n",
      "0.8000438950483554 0.583105464574535\n",
      "7.1904000705326725\n",
      "0.8000438950483554 0.583105464574535\n",
      "7.1904000705326725\n",
      "0.8000438950483554 0.583105464574535\n",
      "0.8000438950483554 0.583105464574535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR6,K,MAT6)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.251687131862756\n",
      "0.7885108250853121 0.5613810282686443\n",
      "7.251687131862756\n",
      "0.7885108250853121 0.5613810282686443\n",
      "7.251687131862756\n",
      "0.7885108250853121 0.5613810282686443\n",
      "0.7885108250853121 0.5613810282686443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR7,K,MAT7)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.394946520236071\n",
      "0.8002633702901321 0.5823181971978003\n",
      "7.394946520236071\n",
      "0.8002633702901321 0.5823181971978003\n",
      "7.394946520236071\n",
      "0.8002633702901321 0.5823181971978003\n",
      "0.8002633702901321 0.5823181971978003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ri = 0\n",
    "ari = 0\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    l = stableClustering(GEN_TR8,K,MAT8)\n",
    "    #l3 = getLabelResult(center)\n",
    "    ri = ri + RI(baseline,l)\n",
    "    ari = ari + adjusted_rand_score(baseline,l)\n",
    "    print(RI(baseline,l),adjusted_rand_score(baseline,l))\n",
    "print(ri/N,ari/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
